{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration: \n",
    "https://medium.com/mlearning-ai/time-series-forecasting-with-xgboost-and-lightgbm-predicting-energy-consumption-460b675a9cee\n",
    "\n",
    "Vorgehen:\n",
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html\n",
    "\n",
    "\n",
    "10000 Variablen: \n",
    "- Sonst HistGradientBoost besser, allerdings keine Quantile Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-01 21:00:00\n",
      "2023-11-23 12:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from energy_consumption.feature_selection.extract import extract_energy_data, extract_all_features\n",
    "from energy_consumption.help_functions import get_forecast_timestamps, create_submission_frame\n",
    "\n",
    "energydata = pd.read_csv(\n",
    "    'c:\\\\Users\\\\Maria\\\\Documents\\\\Studium\\\\Pyhton Projekte\\\\PTSFC\\\\energy_consumption\\\\feature_selection\\\\data\\\\historical_data.csv')\n",
    "energydata['date_time'] = pd.to_datetime(\n",
    "    energydata['date_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "energydata = energydata.set_index(\"date_time\")[-10000:]\n",
    "\n",
    "energydata_xgb = extract_all_features.get_energy_and_standardized_features(\n",
    "    energydata, knn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning: \n",
    "* To find the best hyperparameters for your GradientBoostingRegressor, you can use a hyperparameter tuning approach\n",
    "* One commonly used method is GridSearchCV or RandomizedSearchCV \n",
    "* scikit-learnscikit-learn's current version doesn't directly support quantile regression as a loss function in its grid search\n",
    "\n",
    "--> create custom scorer for quantile loss and use it with GridSearchCV or RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for 0.025 {'n_estimators': 300, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_depth': 4, 'learning_rate': 0.01}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for 0.25 {'n_estimators': 300, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_depth': 4, 'learning_rate': 0.01}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for 0.5 {'n_estimators': 300, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_depth': 4, 'learning_rate': 0.01}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for 0.75 {'n_estimators': 300, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_depth': 4, 'learning_rate': 0.01}\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for 0.975 {'n_estimators': 300, 'min_samples_split': 11, 'min_samples_leaf': 13, 'max_depth': 4, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "y = energydata[['energy_consumption']]\n",
    "X = energydata.drop(columns=['energy_consumption'])\n",
    "\n",
    "# Define the quantile loss function as a scorer\n",
    "def pinball_loss_scorer(y_true, y_pred, alpha):\n",
    "    errors = y_true - y_pred\n",
    "    mask = errors < 0\n",
    "    loss = alpha * np.sum(errors[mask]) + (1 - alpha) * np.sum(-errors[~mask])\n",
    "    return loss / len(y_true)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_leaf': list(range(5,15)),\n",
    "    'min_samples_split': list(range(5,15))\n",
    "}\n",
    "\n",
    "# Create the time series split\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=100)\n",
    "best_parameters = {}\n",
    "\n",
    "for alpha in [0.025, 0.25, 0.5, 0.75, 0.975]:\n",
    "\n",
    "    # Create a custom scorer for quantile loss\n",
    "    quantile_scorer = make_scorer(\n",
    "        pinball_loss_scorer, greater_is_better=False, alpha=alpha)\n",
    " \n",
    "    # Create the GradientBoostingRegressor model\n",
    "    gbr = GradientBoostingRegressor(loss=\"quantile\", alpha=alpha)\n",
    "\n",
    "    # Create the RandomizedSearchCV object\n",
    "    random_search = RandomizedSearchCV(\n",
    "        gbr,\n",
    "        param_distributions=param_grid,\n",
    "        scoring=quantile_scorer,\n",
    "        cv=tscv,\n",
    "        n_iter=5,  # Adjust the number of iterations based on your computational resources\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    random_search.fit(X, y.values.ravel())\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    print(f\"Best Hyperparameters for {alpha}\", best_params)\n",
    "    best_parameters.update({alpha: best_params}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_pinball_loss\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "y_train, y_test = energydata[['energy_consumption']\n",
    "                             ][:-100], energydata[['energy_consumption']][-100:]\n",
    "X_train, X_test = energydata.drop(columns=['energy_consumption'])[\n",
    "    :-100], energydata.drop(columns=['energy_consumption'])[-100:]\n",
    "\n",
    "common_params = dict(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    max_depth=2,\n",
    "    min_samples_leaf=9,\n",
    "    min_samples_split=9,\n",
    ")\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "pinball_losses = {}\n",
    "for alpha in [0.025, 0.25, 0.5, 0.75, 0.975]:\n",
    "    name = f'q{alpha}'\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        loss=\"quantile\", alpha=alpha, **common_params)\n",
    "    quantile_model = gbr.fit(X_train, y_train)\n",
    "    y_pred = quantile_model.predict(X_test)\n",
    "\n",
    "    predictions[name] = y_pred\n",
    "    pinball_losses.update({name: mean_pinball_loss(y_test, y_pred, alpha = alpha)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q0.025': 0.30979839619128274,\n",
       " 'q0.25': 1.859079794576308,\n",
       " 'q0.5': 2.263016476483537,\n",
       " 'q0.75': 1.6353804454129328,\n",
       " 'q0.975': 0.33482661538517966}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinball_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with selected parameters \n",
    "* Light comparison to be sure that my scoring function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Maria\\Documents\\Setups\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'q0.025': 0.31567073467041057,\n",
       " 'q0.25': 1.8421321500418597,\n",
       " 'q0.5': 2.276598038980722,\n",
       " 'q0.75': 1.672949624905699,\n",
       " 'q0.975': 0.34219537731819444}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with selected parameters\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "y_train, y_test = energydata[['energy_consumption']\n",
    "                             ][:-100], energydata[['energy_consumption']][-100:]\n",
    "X_train, X_test = energydata.drop(columns=['energy_consumption'])[\n",
    "    :-100], energydata.drop(columns=['energy_consumption'])[-100:]\n",
    "\n",
    "optimized_params = dict(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=13,\n",
    "    min_samples_split=11,\n",
    ")\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "pinball_losses = {}\n",
    "for alpha in [0.025, 0.25, 0.5, 0.75, 0.975]:\n",
    "    name = f'q{alpha}'\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        loss=\"quantile\", alpha=alpha, **optimized_params)\n",
    "    quantile_model = gbr.fit(X_train, y_train)\n",
    "    y_pred = quantile_model.predict(X_test)\n",
    "\n",
    "    predictions[name] = y_pred\n",
    "    pinball_losses.update(\n",
    "        {name: mean_pinball_loss(y_test, y_pred, alpha=alpha)})\n",
    "\n",
    "pinball_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from energy_consumption.feature_selection.extract import extract_energy_data, extract_all_features\n",
    "from energy_consumption.help_functions.drop_years import drop_years\n",
    "from energy_consumption.help_functions import get_forecast_timestamps, create_submission_frame\n",
    "\n",
    "optimized_params = dict(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=13,\n",
    "    min_samples_split=11,\n",
    ")\n",
    "\n",
    "\n",
    "def get_XGBoost_forecasts(energydata=np.nan, indexes=[47, 51, 55, 71, 75, 79], quantiles=[0.025, 0.25, 0.5, 0.75, 0.975], periods=100):\n",
    "\n",
    "    if type(energydata) == float:\n",
    "        # use derived optimum for number of years\n",
    "        energydata = extract_energy_data.get_data(num_years=7)\n",
    "\n",
    "    energydata = extract_all_features.get_energy_and_standardized_features(\n",
    "        energydata, knn=True)\n",
    "\n",
    "    X = energydata.drop(columns=['energy_consumption'])\n",
    "    y = energydata['energy_consumption']\n",
    "\n",
    "    # create dataframe to store forecast quantiles\n",
    "    energyforecast = get_forecast_timestamps.forecast_timestamps(\n",
    "        energydata.index[-1])\n",
    "\n",
    "    X_pred = extract_all_features.get_energy_and_standardized_features(\n",
    "        energyforecast, knn=True)\n",
    "\n",
    "    X, X_pred = drop_years(X, X_pred)\n",
    "\n",
    "    quantile_df = pd.DataFrame()\n",
    "    for alpha in [0.025, 0.25, 0.5, 0.75, 0.975]:\n",
    "        name = f'q{alpha}'\n",
    "        gbr = GradientBoostingRegressor(\n",
    "            loss=\"quantile\", alpha=alpha, **optimized_params)\n",
    "        quantile_model = gbr.fit(X, y)\n",
    "        y_pred = quantile_model.predict(X_pred)\n",
    "        quantile_df[name] = y_pred\n",
    "\n",
    "    quantile_df = quantile_df.iloc[indexes]\n",
    "\n",
    "    # return quantile forecasts in terms of absolute evaluation\n",
    "    abs_eval = (len(quantiles) != 5)\n",
    "    if abs_eval == True:\n",
    "        print('true')\n",
    "        horizon = pd.date_range(start=energydata.index[-1] + pd.DateOffset(\n",
    "            hours=1), periods=periods, freq='H')\n",
    "        quantile_df.insert(\n",
    "            0, 'date_time', [horizon[i] for i in indexes])\n",
    "\n",
    "        return quantile_df\n",
    "\n",
    "    # else: create submission frame\n",
    "    else:\n",
    "        forecast_frame = create_submission_frame.get_frame(\n",
    "            quantile_df, indexes)\n",
    "        forecast_frame = forecast_frame.drop(columns={'index'})\n",
    "        horizon = pd.date_range(start=energydata.index[-1] + pd.DateOffset(\n",
    "            hours=1), periods=periods, freq='H')\n",
    "        forecast_frame.insert(\n",
    "            0, 'date_time', [horizon[i] for i in indexes])\n",
    "\n",
    "        return forecast_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-01 21:00:00\n",
      "2023-11-23 12:00:00\n",
      "2023-11-22 13:00:00\n",
      "2023-11-27 16:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-24 12:00:00</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>energy</td>\n",
       "      <td>36 hour</td>\n",
       "      <td>40.140204</td>\n",
       "      <td>50.116355</td>\n",
       "      <td>58.446340</td>\n",
       "      <td>62.239184</td>\n",
       "      <td>64.565509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-24 16:00:00</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>energy</td>\n",
       "      <td>40 hour</td>\n",
       "      <td>40.140204</td>\n",
       "      <td>50.116355</td>\n",
       "      <td>56.350162</td>\n",
       "      <td>59.042676</td>\n",
       "      <td>63.085466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-24 20:00:00</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>energy</td>\n",
       "      <td>44 hour</td>\n",
       "      <td>40.140204</td>\n",
       "      <td>50.116355</td>\n",
       "      <td>56.350162</td>\n",
       "      <td>59.042676</td>\n",
       "      <td>63.085466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-25 12:00:00</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>energy</td>\n",
       "      <td>60 hour</td>\n",
       "      <td>42.342401</td>\n",
       "      <td>48.282368</td>\n",
       "      <td>54.015180</td>\n",
       "      <td>55.796100</td>\n",
       "      <td>67.074725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-25 16:00:00</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>energy</td>\n",
       "      <td>64 hour</td>\n",
       "      <td>42.342401</td>\n",
       "      <td>48.282368</td>\n",
       "      <td>52.765690</td>\n",
       "      <td>53.970208</td>\n",
       "      <td>65.702731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-25 20:00:00</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>energy</td>\n",
       "      <td>68 hour</td>\n",
       "      <td>42.342401</td>\n",
       "      <td>48.282368</td>\n",
       "      <td>52.765690</td>\n",
       "      <td>53.970208</td>\n",
       "      <td>65.702731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time forecast_date  target  horizon     q0.025      q0.25  \\\n",
       "0 2023-11-24 12:00:00    2024-01-15  energy  36 hour  40.140204  50.116355   \n",
       "1 2023-11-24 16:00:00    2024-01-15  energy  40 hour  40.140204  50.116355   \n",
       "2 2023-11-24 20:00:00    2024-01-15  energy  44 hour  40.140204  50.116355   \n",
       "3 2023-11-25 12:00:00    2024-01-15  energy  60 hour  42.342401  48.282368   \n",
       "4 2023-11-25 16:00:00    2024-01-15  energy  64 hour  42.342401  48.282368   \n",
       "5 2023-11-25 20:00:00    2024-01-15  energy  68 hour  42.342401  48.282368   \n",
       "\n",
       "        q0.5      q0.75     q0.975  \n",
       "0  58.446340  62.239184  64.565509  \n",
       "1  56.350162  59.042676  63.085466  \n",
       "2  56.350162  59.042676  63.085466  \n",
       "3  54.015180  55.796100  67.074725  \n",
       "4  52.765690  53.970208  65.702731  \n",
       "5  52.765690  53.970208  65.702731  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts = get_XGBoost_forecasts(energydata)\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-11-24 12:00:00</td>\n",
       "      <td>40.185449</td>\n",
       "      <td>50.057719</td>\n",
       "      <td>58.344628</td>\n",
       "      <td>62.222855</td>\n",
       "      <td>64.500873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2023-11-24 16:00:00</td>\n",
       "      <td>40.185449</td>\n",
       "      <td>50.057719</td>\n",
       "      <td>56.241971</td>\n",
       "      <td>59.034353</td>\n",
       "      <td>63.082008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2023-11-24 20:00:00</td>\n",
       "      <td>40.185449</td>\n",
       "      <td>50.057719</td>\n",
       "      <td>56.241971</td>\n",
       "      <td>59.034353</td>\n",
       "      <td>63.082008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2023-11-25 12:00:00</td>\n",
       "      <td>42.418319</td>\n",
       "      <td>48.213743</td>\n",
       "      <td>54.111461</td>\n",
       "      <td>55.889315</td>\n",
       "      <td>67.025330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2023-11-25 16:00:00</td>\n",
       "      <td>42.418319</td>\n",
       "      <td>48.213743</td>\n",
       "      <td>52.794317</td>\n",
       "      <td>54.021648</td>\n",
       "      <td>65.750325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2023-11-25 20:00:00</td>\n",
       "      <td>42.418319</td>\n",
       "      <td>48.213743</td>\n",
       "      <td>52.794317</td>\n",
       "      <td>54.021648</td>\n",
       "      <td>65.750325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time     q0.025      q0.25       q0.5      q0.75     q0.975\n",
       "47 2023-11-24 12:00:00  40.185449  50.057719  58.344628  62.222855  64.500873\n",
       "51 2023-11-24 16:00:00  40.185449  50.057719  56.241971  59.034353  63.082008\n",
       "55 2023-11-24 20:00:00  40.185449  50.057719  56.241971  59.034353  63.082008\n",
       "71 2023-11-25 12:00:00  42.418319  48.213743  54.111461  55.889315  67.025330\n",
       "75 2023-11-25 16:00:00  42.418319  48.213743  52.794317  54.021648  65.750325\n",
       "79 2023-11-25 20:00:00  42.418319  48.213743  52.794317  54.021648  65.750325"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe: Try out different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_depth\": list(range(1, 7)),\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
